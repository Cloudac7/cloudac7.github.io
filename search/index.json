[{"content":"可能有人看到这个标题便会有疑问，照理说 Slurm 21.08 以上已经提供了 MIG 支持，只要按照官方文档上的指引便可以正确运行。\n但情况并没有这么简单，因为官方文档中提到的 AutoDetect=nvml 特性实际上需要在配置/编译 Slurm 时确保 --with-nvml 特性开启，且需要正确安装 NVML 库来支持。 由于 Slurm 通常是集群建设时由厂商工程师部署，往往并没有编译这一特性支持。于是要想开启这一功能，我们需要对 Slurm 进行重新编译或寻找满足要求的二进制包……\n作为一个简单的 Work Around，本文自然未打算对这个情况进行说明。因此我们退而求其次，选择并非基于 AutoDetect=nvml 的方案，即手动配置。\n若要人工配置 MIG 硬件，我们需要在 Slurm 的 gres.conf 中写入 MIG 对应的硬件挂载路径。根据官方文档，每一个 MIG 实例都挂载为一个 /dev/nvidia-caps/nvidia-cap* 设备，则通过指定这些路径便可以正确配置硬件信息。\n这里我们先事先创建好 MIG 实例，例如在开启了 MIG 特性支持的 2 和 3 号 GPU 上通过运行：\n1 sudo nvidia-smi mig -i 2,3 -cgi 19,19,19,19,19,19,19 -C 便可以创建 14 个显存大小约 10G 的 GPU 计算实例，通过 nvidia-smi 可以看到：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 +---------------------------------------------------------------------------------------+ | NVIDIA-SMI 535.129.03 Driver Version: 535.129.03 CUDA Version: 12.2 | |-----------------------------------------+----------------------+----------------------+ | GPU Name Persistence-M | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |=========================================+======================+======================| | 0 NVIDIA A100 80GB PCIe Off | 00000000:17:00.0 Off | 0 | | N/A 46C P0 63W / 300W | 4MiB / 81920MiB | 0% Default | | | | Disabled | +-----------------------------------------+----------------------+----------------------+ | 1 NVIDIA A100 80GB PCIe Off | 00000000:65:00.0 Off | 0 | | N/A 50C P0 76W / 300W | 4MiB / 81920MiB | 0% Default | | | | Disabled | +-----------------------------------------+----------------------+----------------------+ | 2 NVIDIA A100 80GB PCIe Off | 00000000:CA:00.0 Off | On | | N/A 46C P0 64W / 300W | 87MiB / 81920MiB | N/A Default | | | | Enabled | +-----------------------------------------+----------------------+----------------------+ | 3 NVIDIA A100 80GB PCIe Off | 00000000:E3:00.0 Off | On | | N/A 49C P0 73W / 300W | 87MiB / 81920MiB | N/A Default | | | | Enabled | +-----------------------------------------+----------------------+----------------------+ +---------------------------------------------------------------------------------------+ | MIG devices: | +------------------+--------------------------------+-----------+-----------------------+ | GPU GI CI MIG | Memory-Usage | Vol| Shared | | ID ID Dev | BAR1-Usage | SM Unc| CE ENC DEC OFA JPG | | | | ECC| | |==================+================================+===========+=======================| | 2 7 0 0 | 12MiB / 9728MiB | 14 0 | 1 0 0 0 0 | | | 0MiB / 16383MiB | | | +------------------+--------------------------------+-----------+-----------------------+ | 2 8 0 1 | 12MiB / 9728MiB | 14 0 | 1 0 0 0 0 | | | 0MiB / 16383MiB | | | +------------------+--------------------------------+-----------+-----------------------+ | 2 9 0 2 | 12MiB / 9728MiB | 14 0 | 1 0 0 0 0 | | | 0MiB / 16383MiB | | | +------------------+--------------------------------+-----------+-----------------------+ | 2 10 0 3 | 12MiB / 9728MiB | 14 0 | 1 0 0 0 0 | | | 0MiB / 16383MiB | | | +------------------+--------------------------------+-----------+-----------------------+ | 2 11 0 4 | 12MiB / 9728MiB | 14 0 | 1 0 0 0 0 | | | 0MiB / 16383MiB | | | +------------------+--------------------------------+-----------+-----------------------+ | 2 12 0 5 | 12MiB / 9728MiB | 14 0 | 1 0 0 0 0 | | | 0MiB / 16383MiB | | | +------------------+--------------------------------+-----------+-----------------------+ | 2 13 0 6 | 12MiB / 9728MiB | 14 0 | 1 0 0 0 0 | | | 0MiB / 16383MiB | | | +------------------+--------------------------------+-----------+-----------------------+ | 3 7 0 0 | 12MiB / 9728MiB | 14 0 | 1 0 0 0 0 | | | 0MiB / 16383MiB | | | +------------------+--------------------------------+-----------+-----------------------+ | 3 8 0 1 | 12MiB / 9728MiB | 14 0 | 1 0 0 0 0 | | | 0MiB / 16383MiB | | | +------------------+--------------------------------+-----------+-----------------------+ | 3 9 0 2 | 12MiB / 9728MiB | 14 0 | 1 0 0 0 0 | | | 0MiB / 16383MiB | | | +------------------+--------------------------------+-----------+-----------------------+ | 3 11 0 3 | 12MiB / 9728MiB | 14 0 | 1 0 0 0 0 | | | 0MiB / 16383MiB | | | +------------------+--------------------------------+-----------+-----------------------+ | 3 12 0 4 | 12MiB / 9728MiB | 14 0 | 1 0 0 0 0 | | | 0MiB / 16383MiB | | | +------------------+--------------------------------+-----------+-----------------------+ | 3 13 0 5 | 12MiB / 9728MiB | 14 0 | 1 0 0 0 0 | | | 0MiB / 16383MiB | | | +------------------+--------------------------------+-----------+-----------------------+ | 3 14 0 6 | 12MiB / 9728MiB | 14 0 | 1 0 0 0 0 | | | 0MiB / 16383MiB | | | +------------------+--------------------------------+-----------+-----------------------+ +---------------------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=======================================================================================| | No running processes found | +---------------------------------------------------------------------------------------+ 但若使用 ls -1 /dev/nvidia-caps/nvidia-cap* 去查询挂载路径，就会发现下面给出的项目可能会远远多于我们实际创建的 MIG 实例数量。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 /dev/nvidia-caps/nvidia-cap1 /dev/nvidia-caps/nvidia-cap2 /dev/nvidia-caps/nvidia-cap336 /dev/nvidia-caps/nvidia-cap337 /dev/nvidia-caps/nvidia-cap345 /dev/nvidia-caps/nvidia-cap346 /dev/nvidia-caps/nvidia-cap354 /dev/nvidia-caps/nvidia-cap355 /dev/nvidia-caps/nvidia-cap363 /dev/nvidia-caps/nvidia-cap364 /dev/nvidia-caps/nvidia-cap372 /dev/nvidia-caps/nvidia-cap373 /dev/nvidia-caps/nvidia-cap381 /dev/nvidia-caps/nvidia-cap382 /dev/nvidia-caps/nvidia-cap390 /dev/nvidia-caps/nvidia-cap391 /dev/nvidia-caps/nvidia-cap471 /dev/nvidia-caps/nvidia-cap472 /dev/nvidia-caps/nvidia-cap480 /dev/nvidia-caps/nvidia-cap481 /dev/nvidia-caps/nvidia-cap489 /dev/nvidia-caps/nvidia-cap490 /dev/nvidia-caps/nvidia-cap507 /dev/nvidia-caps/nvidia-cap508 /dev/nvidia-caps/nvidia-cap516 /dev/nvidia-caps/nvidia-cap517 /dev/nvidia-caps/nvidia-cap525 /dev/nvidia-caps/nvidia-cap526 /dev/nvidia-caps/nvidia-cap534 /dev/nvidia-caps/nvidia-cap535 实际上上面的路径数量足足有 32 个，显然我们只有 14 个 GPU 实例。于是陷入僵局，到底哪些路径是可用的呢？\n这里我们参考了这篇博客的思路，从中找到真正发挥作用的设备。\n文中提到，通过开启 A100 的 DEVFS 模式，便可以通过 /dev 来指定对应的 MIG 实例。当然由于我们的驱动远远高于 450 版本，故已经默认开启了 DEVFS 模式。 此时，若运行以下命令，我们便令 migconfig 和 migmonitor 生效。\n1 2 3 nvidia-modprobe \\ -f /proc/driver/nvidia/capabilities/mig/config \\ -f /proc/driver/nvidia/capabilities/mig/monitor 这样，当创建实例时，我们便可以从 /proc/driver/nvidia-caps/mig-minors 中得到创建的 MIG 实例所对应的的设备编号，查询的方式便是 gpu\u0026lt;gpu id\u0026gt;/gi\u0026lt;gpu instance id\u0026gt;/ci\u0026lt;compute instance id\u0026gt;。\n例如对上面的 nvidia-smi 输出中的第一个设备：\n1 2 3 4 5 6 7 8 9 10 +---------------------------------------------------------------------------------------+ | MIG devices: | +------------------+--------------------------------+-----------+-----------------------+ | GPU GI CI MIG | Memory-Usage | Vol| Shared | | ID ID Dev | BAR1-Usage | SM Unc| CE ENC DEC OFA JPG | | | | ECC| | |==================+================================+===========+=======================| | 2 7 0 0 | 12MiB / 9728MiB | 14 0 | 1 0 0 0 0 | | | 0MiB / 16383MiB | | | +------------------+--------------------------------+-----------+-----------------------+ 即在 GPU2 上创建的 7 号实例对应的编号 (GPU:2, GI: 7, CI: 0)，即可：\n1 2 cat /proc/driver/nvidia-caps/mig-minors | grep \u0026#34;gpu2/gi7/ci0\u0026#34; gpu2/gi7/ci0 337 即 /dev/nvidia-caps/nvidia-cap/nvidia-cap337。\n通过类似的操作我们便可以得到每个 MIG 实例所对应的挂载路径，从而可以在 gres.conf 中写入类似于以下的行：\n1 2 3 # 未开启 MIG 的 NodeName=c51-g002 Name=gpu Type=a100 File=/dev/nvidia[0,1] NodeName=c51-g002 Name=gpu Type=1g.10gb File=/dev/nvidia-caps/nvidia-cap[337,346,355,364,373,382,391,472,481,490,508,517,526,535] 然后我们便可将这些设备配置到所需的队列中并用 --gres 来进行指定，例如在 slurm.conf 中：\n1 2 3 4 5 6 # node, gres GresTypes=gpu NodeName=c51-g002 CPUs=64 Sockets=2 CoresPerSocket=16 ThreadsPerCore=2 RealMemory=515275 Gres=gpu:a100:2,gpu:1g.10gb:14 # gpu PartitionName=gpu2 MaxTime=INFINITE Nodes=c51-g002 State=UP 当然如果想要用一行命令直接得到Node配置，可以参考以下的写法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 获取 MIG 设备的 cap 编号 get_cap_numbers() { sudo nvidia-smi mig -lci | awk \u0026#39; /^[|][ ]+[0-9]/ { gsub(/^[|]/, \u0026#34;\u0026#34;); gsub(/[ ]+/, \u0026#34; \u0026#34;); split($0, a, \u0026#34; \u0026#34;); printf \u0026#34;gpu%s/gi%s/ci%s\\n\u0026#34;, a[1], a[2], a[5] }\u0026#39; | while read mig_instance; do grep \u0026#34;$mig_instance\u0026#34; /proc/driver/nvidia-caps/mig-minors | awk \u0026#39;{print $NF}\u0026#39; done | sort -n | uniq | paste -sd, } # 打印新的 GPU 配置 echo \u0026#34;NodeName=c51-g002 Name=gpu Type=1g.10gb File=/dev/nvidia-caps/nvidia-cap[$(get_cap_numbers)]\u0026#34; ","date":"2024-07-05T00:00:00Z","permalink":"https://cloudac7.github.io/p/%E5%88%A9%E7%94%A8slurm%E7%AE%A1%E7%90%86nvidia-mig%E5%AE%9E%E4%BE%8B/","title":"利用Slurm管理NVIDIA MIG实例"},{"content":"Joblib是一款轻量级的Python工作流实现，可以简单快速地把相互独立的循环并行起来，从而节省时间。\n安装 1 pip install joblib 使用方法 以打印出0-9的平方根为例，如果采用直接循环方法，我们可以很简单地写出如下代码。这里用 sleep 来模拟任务本身的延迟：\n1 2 3 4 5 6 7 from math import sqrt from time import sleep from datetime import datetime for i in range(10): print(datetime.now(), sqrt(i)) sleep(1) 输出如下，可见是每秒吐出一个值：\n1 2 3 4 5 6 7 8 9 10 2023-06-15 11:02:01.200605 0.0 2023-06-15 11:02:02.203232 1.0 2023-06-15 11:02:03.207490 1.4142135623730951 2023-06-15 11:02:04.211349 1.7320508075688772 2023-06-15 11:02:05.211646 2.0 2023-06-15 11:02:06.215645 2.23606797749979 2023-06-15 11:02:07.218109 2.449489742783178 2023-06-15 11:02:08.220789 2.6457513110645907 2023-06-15 11:02:09.225884 2.8284271247461903 2023-06-15 11:02:10.229875 3.0 若利用 joblib.Parallel，将循环体写成函数，并把结果作为返回值，则可改写如下：\n1 2 3 4 5 6 7 8 9 10 11 12 from math import sqrt from time import sleep from datetime import datetime from joblib import Parallel, delayed def func(i): result = sqrt(i) print(datetime.now(), result) sleep(1) return result Parallel(n_jobs=2)(delayed(func)(i) for i in range(10)) 可以看到输出如下，由于 n_jobs 设置为2，故每次有2个worker同时运行，每秒得到两个输出：\n1 2 3 4 5 6 7 8 9 10 2023-06-15 11:07:45.843004 0.0 2023-06-15 11:07:45.873286 1.0 2023-06-15 11:07:46.864319 1.4142135623730951 2023-06-15 11:07:46.891164 1.7320508075688772 2023-06-15 11:07:47.871781 2.0 2023-06-15 11:07:47.896673 2.23606797749979 2023-06-15 11:07:48.875107 2.449489742783178 2023-06-15 11:07:48.902218 2.6457513110645907 2023-06-15 11:07:49.880168 2.8284271247461903 2023-06-15 11:07:49.907760 3.0 且最终返回值以一个列表形式列出：\n1 2 3 4 5 6 7 8 9 10 [0.0, 1.0, 1.4142135623730951, 1.7320508075688772, 2.0, 2.23606797749979, 2.449489742783178, 2.6457513110645907, 2.8284271247461903, 3.0] 可见上述代码的效果等价于如下的列表生成式:\n1 [func(i) for i in range(10)] 用这种方法，可以简单快捷地把彼此相互独立的循环体拆解成多个平行任务。当然 n_jobs 的设置请遵循自己使用环境的情况，避免影响到其他人的使用。\n","date":"2023-06-15T00:00:00Z","permalink":"https://cloudac7.github.io/p/joblib-%E7%AE%80%E5%8D%95%E6%98%93%E6%87%82%E7%9A%84%E5%B9%B3%E8%A1%8C%E4%B8%96%E7%95%8C/","title":"joblib: 简单易懂的平行世界"},{"content":" 容器化拯救世界。——沃兹基硕德\n本文是 Containerize Your Life 系列的第2篇博文。\n这一系列旨在用容器化整合、加速环境部署，让读者快速聚焦于生产力，也是一些零散心得的整理。\n没有什么比在一台全新的PC上安装TeXLive更加令人焦躁了。硕大的安装镜像、众多的宏包、令人眼花缭乱的参数设置…… 诚然目前的教程已经足够清晰，考虑到前置步骤依然需要花费一些时间，而阻挡了我们进入专心的码字环节，依然会令人心生几分无奈。 无奈之余，毕业压力裹挟着LaTeX语法来袭，连睡梦里都是\\section{Introduction}……\n有没有什么办法，可以让我们快速部署好TeXLive环境，直接进入写作环节呢？聪明的你看标题便一定能够想到——容器化。\n部署流程 话不多说，直接操练起来。\n首先安装Docker，一般PC直接用Docker Desktop就行，按照安装流程走完便可。\n然后安装好本文的主角——VSCode，并安装 Dev Container 插件 和 LaTeX Workshop 插件、\n创建或进入你的LaTeX项目目录。\n然后 Ctrl+, 进入设置 (Mac是⌘,)。注意如果你不希望改变全局设置，请选择 Workspace 选项卡，则以下配置仅对当前工作区生效。\n搜索 Docker，在左侧目录中找到 LaTeX 分类下的两个选项：latex-workshop.docker.enabled 和 latex-workshop.docker.image.latex。\n根据设置的描述，这两个选项分别对应于是否启用 Docker 环境编译、选择哪个镜像导入。\n于是我们勾选 latex-workshop.docker.enabled，启用，然后在 latex-workshop.docker.image.latex 的文本框中填入：\n1 ghcr.io/xu-cheng/texlive-full 这里我们采用了 Xu Cheng 大佬维护的 TeXLive 容器环境，后者可以提供完整的特性支持。\n在VSCode中，按下 Ctrl+Shift+` 快捷键 (Mac是⌃⇧`) 调出终端，拉取容器：\n1 docker pull ghcr.io/xu-cheng/texlive-full 见证奇迹的时刻：编辑并保存你的tex文件，如果没有语法错误，LaTeX Workshop会自动保存并编译，若编译成功没有报错，便可在当前目录找到编译得到的PDF。右上角按钮提供了分栏功能可以快速预览得到的PDF，从而检查是否有语法错误。\nOne More Trick: Github Action 在当前项目的根目录创建两层目录：.github/workflows，然后在里面创建一个 compile.yaml 文件，定义 Github Action Workflow:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # This is a basic workflow to help you get started with Actions name: Compile LaTeX # Controls when the workflow will run on: # Triggers the workflow on push or pull request events but only for the main branch push: branches: [ master ] pull_request: branches: [ master ] # Allows you to run this workflow manually from the Actions tab workflow_dispatch: # A workflow run is made up of one or more jobs that can run sequentially or in parallel jobs: # This workflow contains a single job called \u0026#34;build\u0026#34; build: # The type of runner that the job will run on runs-on: ubuntu-latest # Steps represent a sequence of tasks that will be executed as part of the job steps: # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it - uses: actions/checkout@v2 - uses: xu-cheng/latex-action@v2 with: root_file: main.tex - uses: actions/upload-artifact@v2.2.4 with: name: main path: main.pdf if-no-files-found: error retention-days: 7 分支请根据自己的情况进行修改，注意 main.tex 对应于你希望编译的主文件名，若为其他的，请对应修改，编译后的PDF文件名默认与之对应，所以下面的path也请对应修改。以上Action文件默认保留7天。\n经过以上步骤，每次对 master 分支的提交便会触发一个编译流程，从而可以在Github Action中下载得到的文件供预览。\n","date":"2023-06-03T00:00:00Z","image":"https://cloudac7.github.io/p/containerize-your-life-%E5%AE%B9%E5%99%A8%E5%8C%96latex%E7%8E%AF%E5%A2%83%E5%8A%A9%E5%8A%9B%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C/docker_hu_c87a8a8aae3f7a08.jpg","permalink":"https://cloudac7.github.io/p/containerize-your-life-%E5%AE%B9%E5%99%A8%E5%8C%96latex%E7%8E%AF%E5%A2%83%E5%8A%A9%E5%8A%9B%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C/","title":"Containerize Your Life: 容器化LaTeX环境助力论文写作"},{"content":"虽然不是每个人都喜欢徒增功耗的RGB跑马灯，但不可否认装机时候很多人看到ARGB还是会走不动道，只能安慰自己性能提升200%（）\n那么有没有办法让每天都要面对的终端也显示出彩虹跑马的效果呢？\n这里介绍两个小工具—— figlet 和 lolcat ，联合运用即可得到酷炫的终端字符画。\nFiglet Figlet是一款字符画生成器，可以根据用户输入得到一个酷炫的字符画。例如：\n1 figlet White Spell 可以看到输出如下：\n而且 figlet 可以切换字体，例如使用 isometric3 字体，就可以得到酷炫的3D字符画\n1 ~ figlet -f isometric3 White Spell 更多字体请参考字体示例，在 -f 选项后输入相应的字体即可。\nLolcat 有了第一步作为基础，我们就可以生成酷炫的RGB字符画了。\nlolcat 是一个可以在终端为标准输入显示出彩虹渐变色彩的工具，我们通过其帮助文档一窥其强大实力。\n可以看到 lolcat 支持从文件或者标准输入中获取信息，那么自然地，我们想到通过管道把 figlet 的输出传递给 lolcat ：\n1 figlet White Spell | lolcat 如图，漂亮的彩虹色🌈\nlolcat 的色彩是随机指定的，因而每次运行可能我们都会得到不同的输出。比较不那么碰运气的做法是，我们给定一个随机种子，例如：\n1 figlet White Spell | lolcat -S 114514 就可以得到如图的输出，并且这个值是固定的。对于如何调随机种子，各位应该比我更有经验（x）\n加上 -f 选项把如图的字符画导出到文本格式文件中：\n1 figlet White Spell | lolcat -S 114514 -f \u0026gt; stdout.txt 用Vim打开，我们就可以看到带有颜色格式的字符画了：\n导入到Motd信息 自然地，我们会想到把上面这个文件里的内容全部复制粘贴到 /etc/motd 中，从而在每次登录终端时赏心悦目。但这样的特殊字符串，我们并不能指望剪切板帮助我们搞定一切，你很可能会看到一堆乱码而不是漂亮的字符画。因此高效的做法恰恰是利用文件IO。\n首先检查自己的发行版有没有提供这个文件，若已提供，且希望添加到每次登陆后提示信息的末尾，只需：\n1 sudo cat stdout.txt \u0026gt;\u0026gt; /etc/motd 若未提供，只需复制粘贴即可：\n1 sudo cp stdout.txt /etc/motd 则可在每次登陆到终端时看见提示信息，如图：\n当然你也可以选择先手动创建一个 /etc/motd 文件，在里面添加好必要的信息，再按照上文添加的方式放置到文件末尾。同理，先复制粘贴，再在文件结尾添加需要的信息，也是可以的。\n题外话：对一些Ubuntu用户来说，可能很希望去掉系统自带的牛皮癣。这些文件没有放置在 /etc/motd 下，而是在 /etc/update-motd.d/ 目录中。当然你也可以依样画葫芦，把字符画放在广告里（\n","date":"2023-05-15T00:00:00Z","permalink":"https://cloudac7.github.io/p/%E9%85%B7%E7%82%AB%E7%BB%88%E7%AB%AFbanner%E7%94%9F%E6%88%90%E6%96%B9%E6%B3%95/","title":"酷炫终端Banner生成方法"},{"content":"时过境迁，距离笔者撰写的新时代的快乐科研：WSL2+Docker+EasyConnect+Clash已经过去一年有余。虽然目前新冠已经转为乙类乙管，大学校园封闭、全员核酸的故事已经成为古老的传言，但由于一些原因，笔者目前的日常办公环境游离在校园网之外，需要依靠EasyConnect与校园网内的服务器沟通。由于觊觎MacOS无缝的编程体验很久，加上手上首发购入的小新Pro13接连出现电源、硬盘等故障，遂于去年8月趁教育优惠外加由于新版MacBook Air发布性价比不足旧版不仅不停售而且闲鱼价格水涨船高的神秘时间点入手了M1版本的MacBook Air。因此本文的教程针对MacOS。\n对于EasyConnect，上一篇教程主要目的正是将其封印在Docker之下。实际上发在知乎的版本下也有观众表示不解——我直接用官方客户端不就行了吗，为什么要大费周章搞Docker。当时的原因有二，一是EasyConnect不能对通过WSL 2的流量直接进行代理，二则也是本文的目的，请参考[这个视频](https://www.bilibili.com/video/BV163411Z7BD）。实际上我姑且相信厂商不会作恶，但作为强迫症患者，我无法接受在Apple Silicon平台常驻两个Rosetta 2转译的基于Intel架构编译的程序（\n但是，基于Docker的方法不适用于Apple Silicon平台，经过实测即使是采用Arm版本构建的镜像，由于各种原因仍然无法正确通过Socks5代理。考虑到折腾的麻烦以及校园网需求的迫切性，笔者索性放弃了Docker方案。实际上XMU提供的EasyConnect路由还算干净，基本上只是把校园网网段做了代理，虽然拜此所赐文献数据库需要采用其他方法连接，但整体使用体验还算OK，除了B站、知乎等略有卡顿，其他跟不使用EC比没有很大影响，特别是Clash不受影响。\n清除开机启动项 EasyMonitor和ECAgent两个进程都是开机自动运行的，作为强迫症患者，首先要做的当然是清除开机启动项。\n那么，请在启动台中打开终端（或者iTerm2等等，总之是顺手的终端），输入：\n1 2 sudo rm /Library/LaunchDaemons/com.sangfor.EasyMonitor.plist sudo rm /Library/LaunchAgents/com.sangfor.ECAgentProxy.plist 如提示输入密码，请输入并回车。\n删除证书 然后请重启电脑，打开 钥匙串访问 程序，左侧选择 系统，右侧选择 证书，看到 Sangfor Technologies Inc.，右键选择删除证书即可。\n若证书删除后不久又自动添加回来，请检查是否已经删除开机启动项并重启过。\n脚本封印 启动编辑器编写如下脚本：\n1 2 3 4 5 6 7 #!/bin/bash /Applications/EasyConnect.app/Contents/Resources/bin/EasyMonitor \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp; /Applications/EasyConnect.app/Contents/MacOS/EasyConnect || true # \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp; pkill EasyMonitor pkill ECAgent pkill ECAgentProxy 将该文件放到 $PATH 路径下，取一个自己喜欢的名字，例如easyconnect。\n如果你不知道 $PATH 路径，请运行 echo $PATH 查看。\n封装脚本 每次都在终端运行命令对于需要开终端的工作流来说不算友好。但实际上，MacOS提供了一个自带的途径，可以把Shell脚本封装成App。\n打开 自动操作 程序，点“取消”并再次点击程序坞上的图标，即可弹出新建自动操作的窗口，点击 应用程序 并选取。\n搜索框中搜索Shell，选择 运行Shell脚本，拖拽到右侧，如图：\n在文本框中输入上文编写的脚本路径，比如/Users/user/.local/bin/easyconnect，点击右上角的运行测试一下能否正确弹出EasyConnect程序。若通过，编辑-存储，将创建的应用程序存储在Application中即可。\n这种方式创建的App可以通过启动台直接运行，体验和直接运行EasyConnect接近，且运行前后都会自动清理EC系列进程。\n保险起见 经过实测上述方法即使通过用户权限运行，也仍然会有提权到Root的程序在后台，当然仅限于工作期间，实测并不会写入新的根证书。但作为强迫症，一个补救措施是连接成功后立即手动干掉两个进程，即：\n1 2 pkill EasyMonitor pkill ECAgent 实测二者被kill不会影响连接。\n参考文献 本文参考了众多大佬的讨论，这里一并列出表示感谢。\nEasyConnect 你想干甚？—— 干掉 macOS 版 EasyConnect 的流氓行为 在 macOS 上安全使用 EasyConnect Mac 中将脚本封装为 App macos 深信服的 easyconnect 是怎么做到自动提权到 root 的？\n","date":"2023-04-12T00:00:00Z","permalink":"https://cloudac7.github.io/p/%E9%9A%90%E7%A7%98%E7%9A%84%E8%A7%92%E8%90%BDmacos%E4%B8%8B%E5%B0%81%E5%8D%B0easyconnect%E7%9A%84%E6%9D%83%E5%AE%9C%E4%B9%8B%E8%AE%A1/","title":"隐秘的角落：MacOS下封印EasyConnect的权宜之计"},{"content":" 容器化拯救世界。——沃兹基硕德\n本文是 Containerize Your Life 系列的第1篇博文。\n这一系列旨在用容器化整合、加速环境部署，让读者快速聚焦于生产力，也是一些零散心得的整理。\n新冠疫情之下，封校+实验室关闭，没有办法，只能在宿舍愉快摸鱼工作。由于宿舍的网是电信光纤，而非狭义的校园网，故连接到课题组集群尚需要使用EasyConnect VPN。众所周知，EasyConnect是一款流氓软件，并且WSL2的流量无法通过前者代理，因而需要另寻道路。\n开端：WSL2+Docker 本文WSL运行环境：WSL2+Debian（为什么不是Ubuntu呢，我也想知道www）\n众所周知，微软在Windows 10发布之初，便画了Windows Subsystem for Linux这个大饼，最终在2017年算是把饼端了上来。初代WSL实现了NT内核到Linux内核指令集的互转，但缺乏对更底层特性的支持，包括Docker和CUDA都无法运行，堪称官方版Cygwin。之所以想要升级到WSL2，正是因为其提供了对Docker和CUDA的完整支持。在Windows 11加持下，更是可以通过WSLg直接使用图形界面（且完整支持X11，妈妈再也不用担心我的$DISPLAY配置写不对了）。从而在Windows 11下，可以获得接近原生Linux的完整体验（不愧是连长相都像macOS的一代）。\n如果你仍在使用WSL1，也可以升级到WSL2。如果你的工作更多依赖本地磁盘文件而不需要更底层的应用，也可以停留在WSL1，后者对Windows分区文件读取性能更好。\n而前文提到，WSL2的流量无法通过EasyConnect代理。一个简单的解决方案因而浮现出来，使用EasyConnect的Docker镜像来解决问题。\n目前，@Hagb大佬已经提供了基于EasyConnect Linux客户端封装的Docker镜像。以下仅作简单说明，详细使用方法请参考上述链接。\n首先安装Docker，基本上是一键完成，因而也没有太多注意事项。安装好后记得检查下设置，确保开启了对WSL2的支持。\n一切就绪后我们就可以开始Docker人生了。首先创建配置文件：\n1 touch ~/.easyconn 加载容器：\n1 docker run -d --device /dev/net/tun --cap-add NET_ADMIN -ti -p 127.0.0.1:1080:1080 -p 127.0.0.1:8888:8888 -e EC_VER=7.6.3 -v $HOME/.easyconn:/root/.easyconn -e CLI_OPTS=\u0026#34;-d \u0026lt;vpn_address\u0026gt; -u \u0026lt;username\u0026gt; -p \u0026lt;password\u0026gt;\u0026#34; hagb/docker-easyconnect:cli 注意替换\u0026lt;vpn_address\u0026gt;，\u0026lt;username\u0026gt;，\u0026lt;password\u0026gt;为自己学校/单位的SSLVPN地址、用户名和密码。\n可以在Docker Desktop中点击创建出的容器，查看一下日志（主要是检查下有没有登陆成功）。可能在几次（次数取决于运气，可能0-2）登陆失败后，终于在最下行出现了：\n1 user \u0026#34;\u0026lt;username\u0026gt;\u0026#34; login successfully 说明登陆成功，可以继续愉快玩耍了。\n上述命令中我们映射了两组端口，分别是1080和8888，对应socks和http代理。接下来我们便尝试利用Socks隧道对SSH进行代理。Debian下的nc命令似乎并不支持-x选项，因而在百度上直接搜到的教程可能并不能奏效。因此，这里采用其他方案。\n1 2 sudo apt update sudo apt install connect-proxy 然后配置~/.ssh/config，采用如下格式：\n1 2 3 4 5 Host \u0026lt;cluster\u0026gt; User \u0026lt;cluster_username\u0026gt; Hostname \u0026lt;cluster_ip\u0026gt; Port \u0026lt;cluster_port\u0026gt; ProxyCommand connect-proxy -S localhost:1080 %h %p 请务必替换上文中信息为自己的用户名、IP、端口等。当然Hostname可以随便取。\n然后测试一下是否可以正常连接：\n1 ssh \u0026lt;cluster\u0026gt; 如果看到了登陆成功信息，说明你的EasyConnect已经正确配置在WSL上。\n进阶：Clash配置Socks定向转发 但上述方法仅适用于WSL2内部的SSH，如果需要在Windows本体使用SSH（比如VSCode的Remote，舒爽程度可谓谁用谁知道），尚且需要想办法通过Socks进行代理。同时，作为一个合格的科研人，科学的上网工具自然是必备，后者可以帮助我们合理使用404搜索引擎快速检索所需的文献。但科学上网工具很多也同样基于Socks5代理，甚至可能存在端口冲突（不少客户端默认使用1080端口）。\nClash作为功能强大的多平台代理客户端，可以方便地解决Socks代理问题。\n首先安装Clash客户端（如果有的话跳过此步）。\n运行，点击config.yaml右侧的\u0026lt;\u0026gt;，进入规则编辑。\n在配置文件中，添加以下代理组（放置在proxies下）：\n1 2 3 4 5 proxies: - name: \u0026#34;vpn1\u0026#34; type: socks5 server: 127.0.0.1 port: 1080 这里的端口是我们上文映射的1080端口。Clash默认采用7890端口，故其他代理不会与之冲突。\n然后在规则组中添加以下条目：\n1 2 3 rules: - IP-CIDR,xxx.xxx.xxx.0/24,vpn1 - IP-CIDR,xxx.xxx.xxx.xxx/32,vpn1 这里的写法请参考[CIDR转换表](CIDR Conversion Table | HPE Edgeline Docs)。第一行表示xxx.xxx.xxx.1直到xxx.xxx.xxx.254的所有IP，第二行则表示只包括xxx.xxx.xxx.xxx这一个IP地址。注意这里的vpn1对应proxies中的name字段。\n保存，如果没有报错说明正确。然后检查需要校园网权限的网站，若可以访问，说明配置成功。\n但聪明的你可能已经发现，PowerShell下的SSH还是没走代理啊？\n是的，我们还需要额外一步：开启TUN模式。这样CFW可以接管非系统代理应用的流量。\n详细步骤请参考官方文档，对0.19.0以上版本，只需进行以下两步：\n点击General中Service Mode右边Manage，在打开窗口中安装服务模式，安装完成应用会自动重启，Service Mode 右边地球图标变为绿色即安装成功（无法安装参考：这里） 点击General中TUN Mode右边开关启动 TUN 模式 接下来就是见证奇迹的时刻。打开PowerShell，直接输入ssh命令登陆校园网集群，便可以登陆成功，且在Clash的Connecting选项卡可以看到对应的连接。打开VSCode，直接开启Remote，也可以正确识别。\n到这里，我们已经顺利完成了WSL2+Docker+EasyConnect+Clash的全工具链配置。还愣着干啥，赶紧摸🐟啊（x）\nXMU特供：并不万能的SSLVPN 对其他学校的同学们，看到这里可以关掉了。因为我也不知道后面的该怎么写了（x）\n但是对于XMU的同学们来说，似乎还差了点什么。没错，就是CNKI。\n非常遗憾，XMU的SSLVPN只能支持校内IP的代理，换言之包括CNKI和各大期刊的网站，都只能用WebVPN访问。\n因此上文中我只配置了课题组的几个IP，而没有做更进一步的设置。\n好在，@spencerwoo大佬制作了一个网站并开源，可以转换任意网址到BIT的WebVPN。因此我Fork了原仓库并依样画葫芦，制作了适用于XMU的版本——XMU WEBVPN Converter，托管到Github Pages上。\n使用方法非常简单，只需在Original URL中输入原始链接，点击中间的绿色按钮，即可在下方得到转换后的链接。可以选择打开或者复制。\n拜其所赐，我可以直接使用404学术搜索，然后把链接粘贴到这里获取WebVPN地址并访问、下载原始文献。\n妈妈再也不用担心导师在微信群发文献链接了（笑）\n以上，开启疫情下的快乐科研吧♥\n","date":"2022-03-23T00:00:00Z","image":"https://cloudac7.github.io/p/%E6%96%B0%E6%97%B6%E4%BB%A3%E7%9A%84%E5%BF%AB%E4%B9%90%E7%A7%91%E7%A0%94wsl2-docker-easyconnect-clash/docker_hu_c87a8a8aae3f7a08.jpg","permalink":"https://cloudac7.github.io/p/%E6%96%B0%E6%97%B6%E4%BB%A3%E7%9A%84%E5%BF%AB%E4%B9%90%E7%A7%91%E7%A0%94wsl2-docker-easyconnect-clash/","title":"新时代的快乐科研：WSL2+Docker+EasyConnect+Clash"},{"content":"前置准备 既然已经找到这里，应该已经知道如何用 Hugo 构建 Blog 页面，并可能已经了解 Github Pages。因此这里不在介绍 Hugo，如有需要请参考官方文档。\n要想使用 Github Pages 构建静态网站，需要把相关代码放在 Github 仓库，命名为 \u0026lt;username/organization\u0026gt;.github.io。为便于说明，假设用户名为 mira。则仓库主分支目录结构大致如下：\n1 2 3 4 5 6 7 mira.github.io ├── archetypes ├── config.yaml ├── content ├── data ├── static └── themes 创建 SSH Deploy Key 详情请参考文档说明。\n在终端中（Windows可在git-scm终端）创建所需的密钥：\n1 2 3 4 ssh-keygen -t rsa -b 4096 -C \u0026#34;$(git config user.email)\u0026#34; -f gh-pages -N \u0026#34;\u0026#34; # You will get 2 files: # gh-pages.pub (public key) # gh-pages (private key) 在仓库页面选择 Settings 标签，从左侧进入 Deploy Keys 设置，添加新的公钥，将公钥（gh-pages.pub）复制粘贴到 Key 框中，勾选下方的 \u0026ldquo;Allow write access\u0026rdquo;，点击 Save 保存。\n点击左侧的 Secrets， 创建新的密钥，命名为 ACTIONS_DEPLOY_KEY 并将密钥（gh-pages）粘贴到下方框中，点击 Save 保存。\n创建 Workflow 在仓库页面点击 Actions 标签，创建新的工作流（注意选择 set up a workflow yourself），路径为.github/workflows/gh-pages.yml，输入以下内容以创建配置文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 name: github pages on: push: branches: - main # Set a branch to deploy pull_request: jobs: deploy: runs-on: ubuntu-20.04 steps: - uses: actions/checkout@v2 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;latest\u0026#39; # extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 if: github.ref == \u0026#39;refs/heads/main\u0026#39; with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_dir: ./public 其中main分支为仓库主分支，若为 master 请手动替换。Workflow 默认选择创建 gh-pages 分支用于存放 Github Pages 所需文件，默认编译在 public 目录下并提交到该分支。若要更改此分支名，需要在Deploy部分指定：\n1 2 3 4 5 - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_branch: your-branch # default: gh-pages 更多设置请参考 actions-hugo 和 actions-gh-pages。\n设置分支 实际上在工作流配置文件提交后，若 Workflow 建立成功，即可自动开启编译。但此时 Pages 仍然不可访问，原因是第一次编译后需要设置 Pages 分支到 gh-pages。请进入 Settings 中，并向下滚动到 GitHub Pages 设置项配置即可。生效一段时间后，即可访问 http(s)://\u0026lt;username/organization\u0026gt;.github.io。\n","date":"2021-07-08T00:00:00Z","permalink":"https://cloudac7.github.io/p/hugo-github-action-%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E/","title":"Hugo Github Action 配置说明"},{"content":"——这些在TV动画《恋爱小行星》里都没有。\n本文是一篇差评，还请轻喷。\nPart 1 引子 我们把时间拉回2019年2月底，芳文社在Kirara Carat封面宣布《恋爱小行星》动画化，这部探讨天文、地质（后期又加入了气象）的漫画很快便吸引了我的注意。时间来到2019年7月底，彼时《街角魔族》因为其并不足够精美的画面饱受原作党诟病。动画工房在这时悄然拿出一张主视觉图——无尽的星空下，两人携手仰望。浪漫的意境，美好的约定，芳文社x动画工房的梦幻组合，加上刚刚做完《天使降临到我身边》的平牧大辅班底，仿佛预示着一部佳作的诞生。随后的秋天里，恋爱小行星PV1和PV2播放，更将我的这种预期推高。\n但事实并不如我预期的那样顺理成章。\nPart 2 节奏问题 第一话放送后，还算优秀的作画，还算舒缓的节奏，配合上还算恰倒好处的BGM，加上一度冲进200的日亚排名。芳文社上一部这样的动画好像是叫《摇曳露营》来着？别管了，总之就是吹爆。\n但第一话的优秀背后也出现隐忧，并且在随后的几话中突出起来。就是动画放送过程中一直为原作党所诟病的节奏问题。\n其实从第1话就会发现，动画组用24min的内容讲了原作3话左右的故事。但这3话的内容联系性姑且OK，改编到动画体裁，似乎不算太大问题。\n然而到了动画第2话，节奏问题骤然尖锐。这一话动画成功地将原作4话内容塞了进去，包括河边捡石头+BBQ、夜观天象、部刊的制作、组团泡温泉等等。实际上原作的逻辑中，是因为老师执意要看流星结果学生们着了凉（细心的观众可能有印象，这话动画中间卡前米拉打了个喷嚏），顾问老师觉得过意不去给了学生们温泉招待券作为补偿，才有了这样的剧情。\n但在动画中，温泉部分变成了Kirakira创刊号的庆功会。\nKiraKira创刊号的制作在原作是第9话的剧情（虽然在逻辑上顺接原作第3话的描述），而合宿+温泉是4-6话。动画为了叙事方便将这里的顺序改为4→5→9→6，直接导致了米沙姐的提前出场。原作第7话（动画第3话）中写到姐姐是个大妹控，擅长数学推导，并且有着令人捉摸不透的行动力。但这里姐姐就看了一眼米拉的文字直接睡着了。\n原作这一部分是这样的：\n（罗翔老师口气）大家可以把自己给代入一下，这里如果你是姐姐的话，看了一篇妹妹的说明文，有没有可能了一眼就睡着？没有。怎么也得看一会儿吧。漫画用两个格子表现这种变化会不会产生这种误解？不会。但动画在这里表现出来的就像是姐姐直接睡着了，这符合我们经验的认知吗？不符合。所以这里动画的节奏是有问题的。这种问题就来源于本话内容的冗杂。\n类似的问题还出现在第9话，同样是塞了原作4话的内容进去。这次的4个故事涉及到苍向家人提出和米拉同居的方案（原作28话）、樱井前辈给大家巧克力以及铃向憧憬的米沙姐表达心意（原作29话）、前辈们的毕业回忆和离别（原作30话）、苍和米拉正式开始同居（原作31话），还附赠新学期引诱部员的一幕（原作32话开头）。动画的处理使得原作至少3个感情非常细腻的场景，都必须在尽可能短的叙事中讲完。做出来的效果，就让感情没有那么饱满，观众还没来得及回忆一下上一幕的感动就被推着进了下一个剧情。\n索性放一段我之前在蓝鹰的帖子下的回复吧。\n毕业照片这段一直到樱和梦露两人约定是第一个篇章，实际上B Part全部安排这一个故事的话，大概恰好能把离别的感情推到最强。虽然是老套的毕业桥段，骗一波眼泪也算OK。但动工没有停下来，继续把米拉和苍同居开始一段放进来，到这里甚至节奏也不算差，除开删减的部分让米拉和苍的吵架显得单薄以外，要旨还算齐全，当苍的角色歌插入的那一刻，又一个充满回忆的点出现了。如果staff表直接在这里出来，或许又是一次ED神插入，再骗一波眼泪说不定也行。但，动工，确切地说是恋星动画制作组，依然没有停下来。于是剧情直接突入新学期，新部员露了个面以后就进入ED，徒留我一脸懵逼，之前胸中积淀的复杂情感荡然无存。\n这种节奏问题如果没有最终话的神操作，其实是可以接受的。因为这使得动画组有机会在12话内塞进原作进度所在的石垣岛篇，从而最大限度地满足协力方的戏份要求（这句是口胡）。最终话最后6分钟，则让动画前面11话赶出来的节奏成了笑话。没错，平牧大辅居然弄了个超长PPT回忆杀展示环节，每个场景出现5-10 s，没有台词，只有BGM，让观众充分地回忆了自己前11话看了些什么，比总集篇还总集篇。这一部分对应原作37话，在原作中是这样表现的：\n这里米拉只用了两格就得出了动画放了好久的回忆才给出的结论。这种PPT式回忆在萌系日常番的一个通常套路是，放完整版ED，一个小窗口放PPT，但动工居然把这个操作放到了正片！？那么前面不惜牺牲细节和感情的赶节奏又算什么呢？综合下来，导致整部动画各话之间的观感参差不齐，每一话都讲了3-4个故事，却又只有一个插入卡。相比之下，讲了比较完整故事的第4话和第11话的单集节奏就好很多。\n可以看到，节奏问题，已经成为整部动画最为突出的问题。\nPart 3 系构问题 但节奏问题的根源来自动画组过于磅礴的野心。没错，他们打算做原作三卷的内容，而37除以12的值稍大于3，所以很自然地动画选择了这样的节奏。归根到底单集的节奏问题，来源于整个剧本的节奏问题，换言之，系构山田由香有着不可推卸的责任。\n实际上动画还没出来、原作党分析剧情的时候普遍认为，动画会做到同居部分结束或者学姐毕业部分，因为这里可以作为一个很自然的结尾。米拉和苍新婚，学姐离开，正是辞旧迎新之际，按照套路，怎么也得渲染一番感情，催催泪什么的。况且31/12的结果也就比2.5大那么一点点，整体完全可以做个2话/集，个别回做3话，应该赶得上。这样每个单集的节奏也就不会太赶，完完全全可以给动画组时间去抒情。\n毕竟，说到天文那就是星空，说到地质那就是大地，说到气象那就是风云，地学这样从大自然直接获取知识和灵感的科学，本就透着一种浪漫气息。这也是原作党以及不少最初关注本作的观众所期待看到的东西。私以为这种浪漫表现得当，会成为芳文社漫改作品里独树一帜的存在。\n但既然动画组选择做到三卷结尾，整个主线就必须做出相应的牺牲，于是可以看到，删减、调整、压缩，无所不用其极。这样的结果，使得浪漫气息大打折扣，故事变成了单纯的日常与科普的堆砌，吸引力也大幅下跌。\n同时，原作的体裁是四格漫画。这种体裁带来的固有属性之一恰恰是话与话之间存在一定的不连续性。恋星原作这个属性的体现尤为明显。实际上，恋星原作很多话是独立成一个故事的，想把这个故事和整个主线联系起来，需要动画制作组在留白的部分下功夫，很考验系构的功力。比如原作的25话和26话，分别讲了小猪第一次挑战地学奥林匹克和地学部圣诞忘年会的事情。两个故事在原作中并没有体现出关联，但在动画却出现在同一话（第8话），且在这两个故事之间没有做任何处理，就可能使得观感上出现一个很大的跳跃。随后，原作26和27话之间，原作是这样的：\n右侧四格顺接随后的搬家线（27话），左侧四格则给这个故事画下一个句号。漫画体裁下这样的处理会不会导致割裂感呢？不会，因为这一话跟下一话之间隔了一个月，观众的情绪波动并不会很大。但动画呢？从苍潸然泪下开始，观众的心情就一定会是：她为何会哭泣呢？这是一处非常适合缓慢叙事拉远镜头到星空开始煽情的片段，随后老师的桥段我觉得甚至可以删除，从而让观众的情绪自然过渡到离别前的悲伤。但动画把这个片段插进来，让情绪始终无法达到饱满，观众也就仿佛置身事外。动画和漫画体裁的最大不同是，漫画的连续性相比动画来的更加薄弱，所以叙事上可以更加跳跃。但这些跳跃的部分对动画观感的影响，处理不好则会导致水土不服。\n另一方面，苍搬家的这条伏线。原作23话（动画相应情节在第7话）中，苍感冒的原因恰恰是妈妈跟她说了这件事以后在澡盆里想念即将分离的米拉，才洗了太久的澡。随后的探病剧情中苍的情绪也有些隐隐的不对，被敏锐的小猪发现了。但动画并没有把这条逻辑脉络展现出来，导致苍搬家的这点直到动画第8话正式引爆才出现。\n还有很多细节的删减，虽然可以说删掉这些笑点让局部气氛与整体气氛相统一，但要是这样的话，为什么不缩减喵内（雾）的戏份呢？\n另一方面就是原作中多如牛毛的科普。这些科普，经常以示意图形式出现，如何让这些示意图在动画体裁中被合理地表现出来，这一点对演出来说是有一定要求的。但很遗憾的是，从实际表现来看，科普很大部分依然是直接给出一个画面，由角色进行解释。观众在看的时候就会有种在上网课的感觉，从而导致了表现力的折扣。\n比如这里，不懂天文学的我是真的没看出来为什么连上米拉指着的那颗星，冬季大钻石便乘了大\u0026quot;G\u0026quot;。更不用说大钻石是怎么看出来的了（\nPart 4 主题 也应看到，动画选择这条路想表达的东西自然有所考量。\n最后是米拉和苍在闪耀星挑战中找到小行星没有？并没有。小猪第一次参加地奥便铩羽而归，信心满满的梦露前辈没能拿到免试入学资格，这都是追逐梦想或者自身价值过程中出现的遗憾。虽然遗憾，但快乐相伴，不管是米拉、苍还是两位学姐，都选择继续扬帆，追逐梦想的彼岸。另一个方面，则是迷惘。樱前辈喜欢矿物到狂热的程度，却并不知道自己真正想做什么，而小猪喜欢的是地图，却并不知道自己该怎么作为部长带领地学部前进，米拉和苍想要找到小行星的约定虽然宏大，但她们具体想要从事的职业又是什么呢？实际上，大家都有擅长或者喜爱的事物，这些领域可能各不相同，但因为相遇、相知、相识，才缀连在一起，构成宛如宇宙般博大的可能性。这一点可能才是Quro太太，以及动画制作组真正想要表达的东西。\n这个概括借米拉之口总结出来，充满浪漫气息，让人想起一句台词，“我们所见的每一个日常，都是奇迹的连续”。\n然而有心是一回事，动画的表现，实际上让这一结论变成了空洞的总结。\n稳定，是芳文系漫改的一大特点。无论是全程高开高走表现出极高素质的露营，还是靠着剧情输出吸引观众的街角，或许也有不够稳定的某个方面，但其最突出的优点往往发挥最稳定。但小行星全程这12话，仅节奏就很难称得上稳定，作画由于疫情原因这里不过多诟病。那么又谈什么稳定输出呢？\n日常萌系作品如今已经有这么多，每一部都有它的独特之处。大家想表达的东西各不相同，但表现出来的又是十人十色的日常。如何做到不泯然众人，是很考验制作组的功力的。\n萌豚番不好做，是句实话。\n","date":"2020-03-28T00:00:00Z","image":"https://cloudac7.github.io/p/%E6%98%9F%E7%A9%BA%E5%A4%A7%E5%9C%B0%E4%B8%8E%E6%97%A5%E5%B8%B8%E7%9A%84%E6%B5%AA%E6%BC%AB%E4%BB%8E%E6%81%8B%E7%88%B1%E5%B0%8F%E8%A1%8C%E6%98%9F%E8%AF%B4%E8%B5%B7/cover_hu_8d4cfc8c4ca5f707.jpg","permalink":"https://cloudac7.github.io/p/%E6%98%9F%E7%A9%BA%E5%A4%A7%E5%9C%B0%E4%B8%8E%E6%97%A5%E5%B8%B8%E7%9A%84%E6%B5%AA%E6%BC%AB%E4%BB%8E%E6%81%8B%E7%88%B1%E5%B0%8F%E8%A1%8C%E6%98%9F%E8%AF%B4%E8%B5%B7/","title":"星空、大地与日常的浪漫——从《恋爱小行星》说起"},{"content":"本次安装的GPU集群无法与外界联网，只有无GPU的管理节点可以使用，故安装过程与官方教程稍有不同。 这里假设远程通过module管理必要的环境，并已经预置了Cuda 9.2和gcc 4.9.4。\n准备工作 首先准备必要的依赖。\n检查可用的模块，并加载必要的模块：\n1 2 3 4 5 module avail module add cuda/9.2 module add gcc/4.9.4 # gcc\u0026gt;=4.9 required by dp_ipi, or it won\u0026#39;t be built. # For gcc-8.3 could not be supported, here we select a lower version. 本教程推荐使用conda虚拟环境安装，故：\n1 2 3 module add miniconda/3.7 conda create -n deepmd python=3.6 conda activate deepmd 下载并编译nccl：\n1 2 3 4 cd /some/nccl_install_path git clone https://github.com/NVIDIA/nccl.git -b v2.4.8-1 cd nccl make -j src.build --prefix=\u0026#34;/some/local/path\u0026#34; NVCC_GENCODE=\u0026#34;-gencode=arch=compute_70,code=sm_70\u0026#34; 由于GPU节点不能直接联网，故使用登陆节点进行编译效率较高，但由于缺少必要的依赖libcuda.so和libcuda.so.1（包含在GPU驱动中，登陆节点未安装），故采用stubs所带的库编译，并手动加入环境变量。\n1 2 ln -s /share/cuda/9.2/lib64/stubs/libcuda.so /some/local/path/libcuda.so.1 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/share/cuda/9.2/lib64/stubs:/some/local/path 在某个想要的路径下将tensorflow-1.12版本的源代码下载好：\n1 2 cd /some/workspace git clone https://github.com/tensorflow/tensorflow tensorflow -b r1.12 --depth=1 下载好bazel安装包并运行，将所需的环境加入环境变量：\n1 2 3 4 wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-installer-linux-x86_64.sh chmod +x bazel-0.15.0-installer-linux-x86_64.sh ./bazel-0.15.0-installer-linux-x86_64.sh --user export PATH=\u0026#34;$PATH:$HOME/bin\u0026#34; tensorflow编译 首先配置tensorflow的编译选项：\n1 2 cd tensorflow/ ./configure 根据需要，提供正确的组件和路径：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 Please specify the location of python. [Default is /xxx]: Found possible Python library paths: /xxx/python3.6/site-packages Please input the desired Python library path to use. Default is [xxx/python3.6/site-packages] Do you wish to build TensorFlow with Apache Ignite support? [Y/n]: Y Do you wish to build TensorFlow with XLA JIT support? [Y/n]: Y Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N Do you wish to build TensorFlow with ROCm support? [y/N]: N Do you wish to build TensorFlow with CUDA support? [y/N]: Y Please specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 9.0]: 9.2 Please specify the location where CUDA 9.2 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /share/cuda/9.2 Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]: 7 Please specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda-10.0]: /share/cuda/9.2 Do you wish to build TensorFlow with TensorRT support? [y/N]: N Please specify the NCCL version you want to use. If NCCL 2.2 is not installed, then you can use version 1.3 that can be fetched automatically but it may have worse performance with multiple GPUs. [Default is 2.2]: 2.4.8 Please specify the location where NCCL 2 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:/some/nccl_install_path/nccl Please note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,7.0] 6.1 Do you want to use clang as CUDA compiler? [y/N]: N Please specify which gcc should be used by nvcc as the host compiler. [Default is /xxx/gcc]: Do you wish to build TensorFlow with MPI support? [y/N]: N Please specify optimization flags to use during compilation when bazel option \u0026#34;--config=opt\u0026#34; is specified [Default is -march=native]: -march=native Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]:N 注意\nCUDA需要写清是9.2版本，否则可能会找不到小版本的依赖库。 1 bazel build --config=opt --copt=-msse4.2 --copt=-mavx --copt=-mavx2 --copt=-mfma --local_resources 2048,.5,1.0 --config=cuda //tensorflow/tools/pip_package:build_pip_package --action_env=\u0026#34;LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\u0026#34; 由于目前节点支持主要的几种优化参数，故可以全部打开以加快运行速度。\n为了他人的正常使用，可以主动限制在登陆节点上编译时的内存和CPU资源使用量。--local_resources 2048,.5,1.0这个设定可能有些保守，但可以保证不会占用过多资源（实测需要11个小时左右，但全程内存占用不超过2G且只使用了一个线程，若觉得太慢可以把中间的参数适当调高）。\nnccl和gcc的路径对应前面加载和编译的环境。 编译如果通过，则再运行以下命令编译c++ interface（实际上一步已经编译好所需的大部分依赖，这一步只是再封装成c++库）：\n1 bazel build -c opt --copt=-msse4.2 --copt=-mavx --copt=-mavx2 --copt=-mfma --config=cuda --verbose_failures //tensorflow:libtensorflow_cc.so --action_env=\u0026#34;LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\u0026#34; 这里可以先将tensorflow-python安装好。\n1 2 ./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg pip install /tmp/tensorflow_pkg/tensorflow-version-tags.whl # depends on your version info 然后，将进行一系列依赖的编译和安装。以防万一，建议首先安装依赖，方便起见，这里使用conda安装。\n1 conda install automake autoconf libtool 将cmake切换到新版本：\n1 module add cmake/3.7.3 指定tf-cc的目标路径为变量$tensorflow_root，并依次运行以下命令：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 mkdir -p $tensorflow_root mkdir /tmp/proto sed -i \u0026#39;s;PROTOBUF_URL=.*;PROTOBUF_URL=\\\u0026#34;https://mirror.bazel.build/github.com/google/protobuf/archive/v3.6.0.tar.gz\\\u0026#34;;g\u0026#39; tensorflow/contrib/makefile/download_dependencies.sh tensorflow/contrib/makefile/download_dependencies.sh cd tensorflow/contrib/makefile/downloads/protobuf/ ./autogen.sh ./configure --prefix=/tmp/proto/ make make install mkdir /tmp/eigen cd ../eigen mkdir build_dir cd build_dir cmake -DCMAKE_INSTALL_PREFIX=/tmp/eigen/ ../ make install mkdir /tmp/nsync cd ../../nsync mkdir build_dir cd build_dir cmake -DCMAKE_INSTALL_PREFIX=/tmp/nsync/ ../ make make install cd ../../absl bazel build mkdir -p $tensorflow_root/include/ rsync -avzh --include \u0026#39;*/\u0026#39; --include \u0026#39;*.h\u0026#39; --exclude \u0026#39;*\u0026#39; absl $tensorflow_root/include/ cd ../../../../.. mkdir $tensorflow_root/lib cp bazel-bin/tensorflow/libtensorflow_cc.so $tensorflow_root/lib/ cp bazel-bin/tensorflow/libtensorflow_framework.so $tensorflow_root/lib/ cp /tmp/proto/lib/libprotobuf.a $tensorflow_root/lib/ cp /tmp/nsync/lib64/libnsync.a $tensorflow_root/lib/ mkdir -p $tensorflow_root/include/tensorflow cp -r bazel-genfiles/* $tensorflow_root/include/ cp -r tensorflow/cc $tensorflow_root/include/tensorflow cp -r tensorflow/core $tensorflow_root/include/tensorflow cp -r third_party $tensorflow_root/include cp -r /tmp/proto/include/* $tensorflow_root/include cp -r /tmp/eigen/include/eigen3/* $tensorflow_root/include cp -r /tmp/nsync/include/*h $tensorflow_root/include cd $tensorflow_root/include find . -name \u0026#34;*.cc\u0026#34; -type f -delete rm -fr /tmp/proto /tmp/eigen /tmp/nsync 以完成c++部分的编译。\nDeePMD-kit安装(1.0+) 首先下载DeePMD-kit，并进入：\n1 2 3 4 cd /some/workspace git clone https://github.com/deepmodeling/deepmd-kit.git cd deepmd-kit deepmd_source_dir=`pwd` 如果前面使用了module load gcc/4.9.4提供的高版本gcc（以4.9.4为例）进行编译，需要手动载入对应的环境变量供cmake识别正确的gcc版本。\n1 2 export CC=/share/apps/gcc/4.9.4/bin/gcc export CXX=/share/apps/gcc/4.9.4/bin/g++ 然后安装dpmd-py\n1 pip install . 如果遇到no module named 'google'或者no module named 'absl'的报错，则可能存在版本bug，需要重新安装依赖。\n1 2 pip install --update protobus pip install --update absl-py 指定DeePMD-kit的目标路径为变量$deepmd_root，随后编译DeePMD-kit C++ Interface：\n1 2 3 4 5 6 cd $deepmd_source_dir/source mkdir build cd build cmake -DTENSORFLOW_ROOT=$tensorflow_root -DCMAKE_INSTALL_PREFIX=$deepmd_root .. make make install 如果运行：\n1 2 3 4 $ ls $deepmd_root/bin dp_ipi $ ls $deepmd_root/lib libdeepmd_ipi.so libdeepmd_op.so libdeepmd.so 得到上述的结果，说明编译成功（若cmake时检测到的是4.8或更低版本的gcc，则编译结果会缺少dp_ipi和libdeepmd_ipi.so）。\nLAMMPS DeePMD-kit 接口编译 首先编译接口：\n1 2 cd $deepmd_source_dir/source/build make lammps 然后下载好稳定版的lammps，并解压：\n1 2 3 cd /some/workspace wget -c https://lammps.sandia.gov/tars/lammps-stable.tar.gz tar xf lammps-stable.tar.gz 若解压后得到目录名为lammps-31Mar17，则\n1 2 cd lammps-31Mar17/src/ cp -r $deepmd_source_dir/source/build/USER-DEEPMD . 打开deepmd module，并根据需要添加所需的模块，以fep为例：\n1 2 make yes-user-deepmd make yes-user-fep 载入需要的mpi库，并编译：\n1 2 3 module load intel/15.0.6 module load mpi/intel/5.0.3.049 make mpi -j4 得到可执行文件：lmp_mpi。\n可将该文件复制到在$PATH中的路径，则可以直接输入文件名运行。\n注意 完成上述安装步骤后，若需要立即测试运行，必须将stubs提供的libcuda.so和libcuda.so.1从环境变量中移除，否则运行时会报错。\n可以直接退出登陆并重新登陆，以免出现该问题。\n一些可能的坑 尽管上述过程应该已经绕过了大部分的坑，但仍不能保证100%安装运行成功。这里记录几种可能的报错的处理方案。\n需要conda init 这种情况已知可能发生在lsf脚本提交的步骤，来源于conda activate deepmd的步骤。具体原因尚不清楚，解决方案是手动载入所需的环境变量。推荐的做法是利用用户自定义module。\n首先，启用自定义module：\n1 module load use.own 然后运行module avail查看自定义脚本的文件位置，输出结果可能如下：\n1 2 3 4 5 6 7 8 ----------- /share/base/modulefiles/compilers ----------- ............ ------------- /usr/share/Modules/modulefiles ------------ dot module-git module-info modules null use.own ------------ /data/home/someuser/privatemodules ------------ null 显示/data/home/someuser/privatemodules是当前用户自定义模块的存放位置。\n则创建路径，并进入：\n1 2 mkdir -p /data/home/someuser/privatemodules cd /data/home/someuser/privatemodules 然后根据想要的名字创建文件或目录。\n比如想以deepmd为模块名，且希望提供不同版本的支持，则可以：\n1 2 mkdir deepmd vim 1.0 编辑1.0文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # Help message proc ModulesHelp { } { set nameversion [module-info name] regsub \u0026#34;/.*\u0026#34; $nameversion \u0026#34;\u0026#34; name regsub \u0026#34;.*/\u0026#34; $nameversion \u0026#34;\u0026#34; version puts stderr \u0026#34;\\tLoads the $version $name environment\u0026#34; } # Set variables set nameversion [module-info name] regsub \u0026#34;/.*\u0026#34; $nameversion \u0026#34;\u0026#34; name regsub \u0026#34;.*/\u0026#34; $nameversion \u0026#34;\u0026#34; version module-whatis \u0026#34;Miniconda, an alternative distirbution for python 3.6\u0026#34; # set environment variables setenv\tPYTHONROOT\t/data/home/someuser/anaconda3/envs/deepmd prepend-path\tPATH\t$env(PYTHONROOT)/bin prepend-path\tMANPATH\t$env(PYTHONROOT)/share/man prepend-path\tPYTHONPATH\t$env(PYTHONROOT)/lib/python3.6/site-packages 注意修改PYTHONROOT为正确的虚拟环境路径（可用conda env list查看）,并且python3.6也要与实际使用的python版本一致。\n这样，便可以通过module调用所需的虚拟环境。\n使用时提交脚本可以这样写：\n1 2 module load use.own module load deepmd/1.0 ","date":"2019-11-01T00:00:00Z","image":"https://cloudac7.github.io/p/deepmd-kit%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98%E5%85%A8%E8%AE%B0%E5%BD%95/cover_hu_e95a4276bf860a84.jpg","permalink":"https://cloudac7.github.io/p/deepmd-kit%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98%E5%85%A8%E8%AE%B0%E5%BD%95/","title":"DeePMD-kit安装实战全记录"}]